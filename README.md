# dialogue_seq2seq

基于知识驱动场景的多轮对话：
1 数据建模层面
  总的思路：拼接goal信息、knowledge信息以及多轮对话信息，中间用[GOAL],[KG], [SEP]分隔。第一部分goal建模，去掉START字符。第二部分 knowledge部分由于知识较多，目前采取根据多轮对话中出现的实体对知识三元组进行筛选，保留跟对话相关的三元组。第三部分：多伦对话，通过分析对话内容看，奇数轮的对话包含了相对较多的知识，更像机器人角色，因此选择奇数轮为需要生成的response轮。
  然后seg构造是，goal和knowledge部分为0， response轮为1，其他轮为0。

2 模型层面
  目前有两个模型：roberta和nezha。
  这两个模型都有基于字和基于词的预训练模型，目前都在尝试，基于词的模型理论上速度和生成效果会更好。
  解码端有两个解码方案，一个是beamsearch，一个是random sample的思路。两者目前random sample的效果稍好。

3 模型评估方案
  训练过程用的bleu，离线预测阶段与官网一致，有f1,bleu,distinct。

4 目前结果
  训练过程bleu值0.1，离线指标还未测，模型还在调整和训练中。经过调优和训练模型之后，bleu稳定在0.14，最终比赛指标提升至0.365。



闲聊场景对话：

模型层面
利用知识建模框架有一定信息指导作用。

1 random sample 解码方案加入过短惩罚，闲聊场景效果提升了一些，预测结果指标提升0.01左右，
2 优化loss方案，改进token的平均loss为整体loss，指标也有所提升。
